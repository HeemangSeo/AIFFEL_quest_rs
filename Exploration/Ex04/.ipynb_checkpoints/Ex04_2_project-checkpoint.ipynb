{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로 설정 (사용자 환경에 맞게 수정 필요)\n",
    "dataset_dir = \"~/work/data_augmentation/data/Images/\"\n",
    "\n",
    "# 기본 Transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "try:\n",
    "    # 데이터셋 로드\n",
    "    full_dataset = ImageFolder(root=dataset_dir, transform=transform)\n",
    "    \n",
    "    # Train/Test Split\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    test_size = total_size - train_size\n",
    "    ds_train, ds_test = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    ds_info = {\n",
    "        \"num_classes\": len(full_dataset.classes),\n",
    "        \"class_names\": full_dataset.classes\n",
    "    }\n",
    "    print(f\"Classes: {ds_info['num_classes']}, Train: {len(ds_train)}, Test: {len(ds_test)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"데이터셋 로드 실패 (경로 확인 필요): {e}\")\n",
    "    # 더미 데이터 (실행 테스트용)\n",
    "    ds_info = {\"num_classes\": 120, \"class_names\": [str(i) for i in range(120)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Helper Functions: Transforms & Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(with_aug=False):\n",
    "    \"\"\"Augmentation 여부에 따른 Transform 반환\"\"\"\n",
    "    base_transforms = [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ]\n",
    "    \n",
    "    if with_aug:\n",
    "        aug_transforms = [\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(brightness=0.2),\n",
    "        ]\n",
    "        return transforms.Compose(aug_transforms + base_transforms)\n",
    "    \n",
    "    return transforms.Compose(base_transforms)\n",
    "\n",
    "def apply_normalize_on_dataset(dataset, is_test=False, batch_size=32, with_aug=False):\n",
    "    \"\"\"DataLoader 생성 함수\"\"\"\n",
    "    # Transform 적용\n",
    "    final_transform = get_transforms(with_aug=with_aug and not is_test)\n",
    "\n",
    "    # Subset인 경우 원본 데이터셋의 transform 속성을 잠시 변경하여 적용하는 방식\n",
    "    # (주의: 실제 운영 환경에서는 Subset에 별도 Transform을 래핑하는 것이 더 안전함)\n",
    "    if hasattr(dataset, 'dataset'):\n",
    "        dataset.dataset.transform = final_transform\n",
    "    else:\n",
    "        dataset.transform = final_transform\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=not is_test,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def mixup(x, y, alpha=1.0):\n",
    "    \"\"\"Mixup Augmentation 함수\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "def mixup_loss(pred, target):\n",
    "    \"\"\"Mixup 적용 시 사용하는 Loss (target은 one-hot 형태여야 함)\"\"\"\n",
    "    log_prob = F.log_softmax(pred, dim=1)\n",
    "    loss = -torch.sum(target * log_prob, dim=1)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "train_loader = apply_normalize_on_dataset(ds_train, is_test=False, batch_size=32, with_aug=True)\n",
    "val_loader = apply_normalize_on_dataset(ds_test, is_test=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Definition (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=120):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64,  num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResNet18(num_classes=120):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
    "\n",
    "# 모델 초기화\n",
    "model = ResNet18(num_classes=ds_info[\"num_classes\"]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training & Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, Scheduler, Loss\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, num_classes, use_mixup=False, mixup_alpha=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if use_mixup:\n",
    "            # Mixup 적용을 위해 Label을 One-hot으로 변환\n",
    "            labels_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "            images, labels_mixed = mixup(images, labels_onehot, alpha=mixup_alpha)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = mixup_loss(outputs, labels_mixed)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 (Mixup 사용 시 argmax로 예측)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_classes = ds_info[\"num_classes\"]\n",
    "\n",
    "print(\"Start Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        num_classes=num_classes,\n",
    "        use_mixup=True, \n",
    "        mixup_alpha=0.4\n",
    "    )\n",
    "    \n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
    "        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet18_mixup.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}